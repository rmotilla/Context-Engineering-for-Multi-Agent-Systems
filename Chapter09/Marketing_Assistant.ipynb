{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "8A-7-9jXuF29"
      ],
      "authorship_tag": "ABX9TyNHyTzDLmsOU3KPFhTAozMo"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Marketing Assistant\n",
        "\n",
        "Copyright 2025, Denis Rothman\n",
        "\n",
        "**Goal:** This notebook serves as the practical runtime for the **Strategic Marketing Engine**, as architected in Chapter 9. It demonstrates how the generic, multi-domain \"Glass Box\" Context Engine can be seamlessly repurposed to solve a variety of real-world marketing challenges without any changes to its core code.\n",
        "\n",
        "This notebook will:\n",
        "* Connect to the Pinecone knowledge base populated by the `Data_Ingestion_Marketing.ipynb` script.\n",
        "* Use the three generic Control Deck templates to interact with the engine.\n",
        "* Execute seven distinct marketing use cases, from enforcing brand voice to drafting a complete email nurture sequence.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hfzZQTDjpfu6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I. Inititalization"
      ],
      "metadata": {
        "id": "zo-XYpI5f3JX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GitHub"
      ],
      "metadata": {
        "id": "a455hFQaWMUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Downloading the utilities and the agents ---\n",
        "\n",
        "# The !curl command is a simple and effective way to download raw files from a public GitHub repo.\n",
        "# The -L flag ensures that it follows any redirects.\n",
        "\n",
        "# print(\"Downloading helper files from public repository...\")\n",
        "# !curl -L https://raw.githubusercontent.com/Denis2054/Context-Engineering/main/commons/utils.py --output utils.py\n",
        "# !curl -L https://raw.githubusercontent.com/Denis2054/Context-Engineering/main/commons/helpers.py --output helpers.py\n",
        "# !curl -L https://raw.githubusercontent.com/Denis2054/Context-Engineering/main/commons/agents.py --output agents.py\n",
        "# !curl -L https://raw.githubusercontent.com/Denis2054/Context-Engineering/main/commons/registry.py.py --output registry.py.py\n",
        "# !curl -L https://raw.githubusercontent.com/Denis2054/Context-Engineering/main/commons/engine.py --output engine.py\n",
        "\n",
        "# print(\"âœ… Files downloaded successfully!\")"
      ],
      "metadata": {
        "id": "KkF91Ki_Xw9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "def download_private_github_file(filename, destination_path=\".\"):\n",
        "    \"\"\"\n",
        "    Downloads a file from a private GitHub repository using a token\n",
        "    stored in Colab Secrets.\n",
        "\n",
        "    Requires a secret named 'GITHUB_TOKEN' to be set in the Colab UI.\n",
        "    \"\"\"\n",
        "    # --- Configuration: Replace with your repository details ---\n",
        "    owner = \"Denis2054\"\n",
        "    repo = \"Context-Engineering\"\n",
        "    branch = \"main\"\n",
        "    # ---------------------------------------------------------\n",
        "\n",
        "    try:\n",
        "        # Securely fetch the GitHub token from Colab Secrets\n",
        "        token = userdata.get('GITHUB_TOKEN')\n",
        "        if not token:\n",
        "            raise userdata.SecretNotFoundError(\"Secret 'GITHUB_TOKEN' not found.\")\n",
        "    except userdata.SecretNotFoundError:\n",
        "        print(\"ðŸ›‘ Error: Secret 'GITHUB_TOKEN' not found.\")\n",
        "        print(\"Please add your GitHub Personal Access Token to the Colab Secrets Manager.\")\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while accessing secrets: {e}\")\n",
        "        return\n",
        "\n",
        "    # Construct the GitHub API URL for the file\n",
        "    url = f\"https://api.github.com/repos/{owner}/{repo}/contents/{filename}?ref={branch}\"\n",
        "\n",
        "    # Prepare headers for authentication and to request the raw file content\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {token}\",\n",
        "        \"Accept\": \"application/vnd.github.v3.raw\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Make the request to the GitHub API\n",
        "        response = requests.get(url, headers=headers)\n",
        "        response.raise_for_status()  # This will raise an HTTPError for bad responses (4xx or 5xx)\n",
        "\n",
        "        # Determine the local filename\n",
        "        local_filename = os.path.join(destination_path, os.path.basename(filename))\n",
        "\n",
        "        # Save the file content locally\n",
        "        with open(local_filename, \"wb\") as f:\n",
        "            f.write(response.content)\n",
        "\n",
        "        print(f\"âœ… Successfully downloaded '{filename}' to '{local_filename}'\")\n",
        "\n",
        "    except requests.exceptions.HTTPError as e:\n",
        "        print(f\"ðŸ›‘ Error downloading '{filename}': {e}\")\n",
        "        if e.response.status_code == 404:\n",
        "            print(\"   Please check that the owner, repo, file path, and branch are correct.\")\n",
        "        elif e.response.status_code == 401:\n",
        "            print(\"   Authentication failed. Please check if your GITHUB_TOKEN is valid and has access to the repo.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "\n",
        "# --- Example Usage: Download your utility files ---\n",
        "# Ensure you have set 'GITHUB_TOKEN' in your Colab Secrets before running this.\n",
        "\n",
        "download_private_github_file(\"commons/ch8/utils.py\")\n",
        "download_private_github_file(\"commons/ch8/helpers.py\")\n",
        "download_private_github_file(\"commons/ch8/agents.py\")\n",
        "download_private_github_file(\"commons/ch8/registry.py\")\n",
        "download_private_github_file(\"commons/ch8/engine.py\")"
      ],
      "metadata": {
        "id": "a9-qdFBYWNuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation and client setup"
      ],
      "metadata": {
        "id": "8A-7-9jXuF29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Installation and Client Setup\n",
        "\n",
        "# Import the setup functions from your new utility file\n",
        "import utils\n",
        "\n",
        "# Run the installation\n",
        "utils.install_dependencies()\n",
        "\n",
        "# Initialize the OpenAI and Pinecone clients\n",
        "client, pc = utils.initialize_clients()"
      ],
      "metadata": {
        "id": "bkx_Oxy7gerq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Context Engine library Import"
      ],
      "metadata": {
        "id": "BYvkF-c9pVn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Import the hardened helper functions (LLM, Embeddings, Pinecone)\n",
        "import helpers\n",
        "\n",
        "# 2. Import the specialist agent functions (Librarian, Researcher, Writer)\n",
        "import agents\n",
        "\n",
        "# 3. Import the AGENT_TOOLKIT object that knows about all the agents\n",
        "from registry import AGENT_TOOLKIT\n",
        "\n",
        "# 4. Import the main context_engine function that orchestrates the entire process\n",
        "from engine import context_engine"
      ],
      "metadata": {
        "id": "P7wL-SSlpfcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Engine Room"
      ],
      "metadata": {
        "id": "8XDZmds95dBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === ENGINE ROOM: The Main Execution Function ===\n",
        "# This function contains all the logic to run the engine.\n",
        "# We define it here so our final cell can be very simple.\n",
        "\n",
        "import logging\n",
        "import pprint\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# In Legal_Compliance_Assistant.ipynb (The \"Engine Room\" cell)\n",
        "\n",
        "def execute_and_display(goal, config, client, pc, moderation_active=False):\n",
        "    \"\"\"\n",
        "    Runs the context engine, now with an optional, two-stage moderation check.\n",
        "    \"\"\"\n",
        "    # --- PRE-FLIGHT MODERATION CHECK (on user input) ---\n",
        "    if moderation_active:\n",
        "        print(\"--- [Safety Guardrail] Performing Pre-Flight Moderation Check on Goal ---\")\n",
        "        moderation_report = helpers.helper_moderate_content(text_to_moderate=goal, client=client)\n",
        "\n",
        "        print(\"Moderation Report:\")\n",
        "        pprint.pprint(moderation_report)\n",
        "\n",
        "        if moderation_report[\"flagged\"]:\n",
        "            print(\"\\nðŸ›‘ Goal failed pre-flight moderation. Execution halted.\")\n",
        "            return # Halt execution before calling the engine\n",
        "\n",
        "    logging.info(f\"******** Starting Engine for Goal: '{goal}' **********\\\\n\")\n",
        "\n",
        "    # 1. Run the Context Engine using the provided configuration\n",
        "    result, trace = context_engine(\n",
        "        goal,\n",
        "        client=client,\n",
        "        pc=pc,\n",
        "        **config\n",
        "    )\n",
        "\n",
        "    # --- POST-FLIGHT MODERATION CHECK (on AI output) ---\n",
        "    if result and moderation_active:\n",
        "        print(\"\\n--- [Safety Guardrail] Performing Post-Flight Moderation Check on Output ---\")\n",
        "        moderation_report = helpers.helper_moderate_content(text_to_moderate=result, client=client)\n",
        "\n",
        "        print(\"Moderation Report:\")\n",
        "        pprint.pprint(moderation_report)\n",
        "\n",
        "        if moderation_report[\"flagged\"]:\n",
        "            print(\"\\nðŸ›‘ Generated output failed post-flight moderation and will be redacted.\")\n",
        "            result = \"[Content flagged as potentially harmful by moderation policy and has been redacted.]\"\n",
        "\n",
        "    # 2. Display the Final Result\n",
        "    print(\"\\n--- FINAL OUTPUT ---\")\n",
        "    if result:\n",
        "        display(Markdown(result))\n",
        "    else:\n",
        "        print(f\"The engine failed to produce a result. Status: {trace.status}\")\n",
        "\n",
        "    # 3. Display the Technical Trace\n",
        "    print(\"\\\\n\\\\n--- TECHNICAL TRACE (for the tech reader) ---\")\n",
        "    if trace:\n",
        "        print(f\"Trace Status: {trace.status}\")\n",
        "        print(f\"Total Duration: {trace.duration:.2f} seconds\")\n",
        "        print(\"Execution Steps:\")\n",
        "        # --- THIS LINE IS TO CREATE THE 'pp' OBJECT ---\n",
        "        pp = pprint.PrettyPrinter(indent=2)\n",
        "\n",
        "        pp.pprint(trace.steps)\n"
      ],
      "metadata": {
        "id": "-ExOs7K95Vgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Control Deck configuration"
      ],
      "metadata": {
        "id": "mQnaOOy-0ds9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define all configuration variables for this run in a dictionary\n",
        "config = {\n",
        "    \"index_name\": 'genai-mas-mcp-ch3',\n",
        "    \"generation_model\": \"gpt-5\",\n",
        "    \"embedding_model\": \"text-embedding-3-small\",\n",
        "    \"namespace_context\": 'ContextLibrary',\n",
        "    \"namespace_knowledge\": 'KnowledgeStore'\n",
        "}"
      ],
      "metadata": {
        "id": "08ghrgVs0ZAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#III.CONTROL DECKS\n",
        "\n",
        "=== CONTROL DECK: Define Goal and Run Engine ===\n",
        "This is the main interactive cell.\n",
        "1. Change the 'goal' variable to your desired task.\n",
        "2. Run this cell.\n"
      ],
      "metadata": {
        "id": "Q16NN3RpuQ40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title CONTROL DECK: Moderation\n",
        "# 1. Define a simple, safe goal to test the moderation workflow.\n",
        "goal = \"Summarize the key points of the Non-Disclosure Agreement.\"\n",
        "\n",
        "# 2. Define the standard configuration.\n",
        "config = {\n",
        "    \"index_name\": 'genai-mas-mcp-ch3',\n",
        "    \"generation_model\": \"gpt-5\",\n",
        "    \"embedding_model\": \"text-embedding-3-small\",\n",
        "    \"namespace_context\": 'ContextLibrary',\n",
        "    \"namespace_knowledge\": 'KnowledgeStore'\n",
        "}\n",
        "\n",
        "# 3. Call the execution function with moderation explicitly activated.\n",
        "execute_and_display(goal, config, client, pc, moderation_active=True)"
      ],
      "metadata": {
        "id": "XOqyUQ6JLuus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title CONTROL DECK TEMPLATE 1: High-Fidelity RAG\n",
        "\n",
        "# 1. Define the Goal: A research query that requires a verifiable, cited answer.\n",
        "#    - DOMAIN: Any knowledge-intensive field (e.g., legal, medical, financial).\n",
        "#    - KEY CAPABILITY: Tests the high-fidelity `Researcher` agent and its ability\n",
        "#      to retrieve text with `source` metadata and generate citations.\n",
        "# goal = \"[INSERT YOUR HIGH-FIDELITY RESEARCH GOAL HERE]\"\n",
        "\n",
        "# === CONTROL DECK 1: High-Fidelity RAG in a Legal Context ===\n",
        "goal = \"What are the key confidentiality obligations in the Service Agreement v1, and what is the termination notice period? Please cite your sources.\"\n",
        "\n",
        "# === CONTROL DECK 1 (LIMIT TEST): Sanitization of Legal Testimony ===\n",
        "#goal = \"What did Mr. Smith advise his client regarding the assets?\"\n",
        "\n",
        "# 2. Use the standard configuration\n",
        "config = {\n",
        "    \"index_name\": 'genai-mas-mcp-ch3',\n",
        "    \"generation_model\": \"gpt-5\", # or your preferred model\n",
        "    \"embedding_model\": \"text-embedding-3-small\",\n",
        "    \"namespace_context\": 'ContextLibrary',\n",
        "    \"namespace_knowledge\": 'KnowledgeStore'\n",
        "}\n",
        "\n",
        "# 3. Call the execution function\n",
        "execute_and_display(goal, config, client, pc,moderation_active=False)"
      ],
      "metadata": {
        "id": "4EC3HmWihJUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #CONTROL DECK 2: Brand Voice Enforcement\n",
        "\n",
        "# 1. Define the Goal: A multi-step task that involves summarizing a large\n",
        "#    document and then using that summary for a different purpose.\n",
        "#    - DOMAIN: Any field with large documents (legal, scientific, corporate).\n",
        "#    - KEY CAPABILITY: Tests the `Summarizer` agent and the engine's ability\n",
        "#      to perform Context Chaining between the `Summarizer` and the `Writer`.\n",
        "# goal = \"[INSERT YOUR CONTEXT REDUCTION GOAL HERE]\"\n",
        "\n",
        "# === STEP 1: Define the Raw Text to be Refined ===\n",
        "\n",
        "# This variable simulates the raw, unpolished output we might get from\n",
        "# a simple query to the Researcher agent.\n",
        "large_text_from_researcher = \"\"\"\n",
        "Check out our new SSD, the QuantumDrive Q-1. It's super fast with speeds up to 7,500 MB/s and it won't overheat thanks to its cool graphene heat spreader. You should totally buy it.\n",
        "\"\"\"\n",
        "\n",
        "print(\"âœ… Raw text defined and ready for refinement.\")\n",
        "\n",
        "# === STEP 2: CONTROL DECK 2 - USE Case 1 Execute Brand Voice Enforcement ===\n",
        "\n",
        "# 1. Define a goal that tells the engine to rewrite the text using the brand guide.\n",
        "# Notice how we use the variable from the cell above as our input.\n",
        "goal = f\"\"\"\n",
        "First, summarize the key points of the official Brand Voice and Tone Guide.\n",
        "Then, using that summary as a strict set of rules, rewrite the following rough draft to be perfectly on-brand.\n",
        "\n",
        "--- TEXT TO REWRITE ---\n",
        "{large_text_from_researcher}\n",
        "\"\"\"\n",
        "\n",
        "# 2. Use the same configuration dictionary\n",
        "config = {\n",
        "    \"index_name\": 'genai-mas-mcp-ch3',\n",
        "    \"generation_model\": \"gpt-5\", # or your preferred model\n",
        "    \"embedding_model\": \"text-embedding-3-small\",\n",
        "    \"namespace_context\": 'ContextLibrary',\n",
        "    \"namespace_knowledge\": 'KnowledgeStore'\n",
        "}\n",
        "\n",
        "# 3. Call the execution function\n",
        "execute_and_display(goal, config, client, pc,moderation_active=False)"
      ],
      "metadata": {
        "id": "f830Ay5RFsU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title CONTROL DECK TEMPLATE 3: Grounded Reasoning & Hallucination Prevention\n",
        "\n",
        "# 1. Define the Goal: A creative or factual task that is deliberately\n",
        "#    outside the scope of the documents in the knowledge base.\n",
        "#    - DOMAIN: Universal test applicable to any curated knowledge base.\n",
        "#    - KEY CAPABILITY: Tests the `Researcher` agent's ability to report a\n",
        "#      negative finding and the `Writer` agent's ability to handle it gracefully,\n",
        "#      preventing hallucination.\n",
        "# goal = \"[INSERT YOUR OUT-OF-SCOPE GOAL HERE]\"\n",
        "\n",
        "\n",
        "# === CONTROL DECK 3: Grounded Reasoning and Hallucination Prevention ===\n",
        "goal = \"Write a persuasive opening statement for a trial involving a monkey that can fly a rocket.\"\n",
        "\n",
        "# === CONTROL DECK 3 (LIMIT TEST): The Ambiguous Request ===\n",
        "#goal = \"Analyze the attached NDA and draft a pleading based on its terms.\"\n",
        "\n",
        "# 2. Use the same configuration dictionary\n",
        "config = {\n",
        "    \"index_name\": 'genai-mas-mcp-ch3',\n",
        "    \"generation_model\": \"gpt-5\", # or your preferred model\n",
        "    \"embedding_model\": \"text-embedding-3-small\",\n",
        "    \"namespace_context\": 'ContextLibrary',\n",
        "    \"namespace_knowledge\": 'KnowledgeStore'\n",
        "}\n",
        "\n",
        "# 3. Call the execution function\n",
        "execute_and_display(goal, config, client, pc,moderation_active=False)"
      ],
      "metadata": {
        "id": "FCAqbBbt5uqh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOoXWAOc51D2wrdV6ShW50S"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Building a Multi-Agent System(MAS) with MCP\n",
        "\n",
        "Copyright 2025-2026, Denis Rothman\n",
        "\n",
        "In this notebook we build a multi agent system from scratch. We will use an educational version of the Model Context Protocol for our agents to communicate. You will learn how to define a standard message format. You will create specialized AI agents like a researcher and a writer. You will also build an orchestrator to manage their workflow. Following the steps you will see how these parts work together. We will turn a high level goal into a finished product like a blog post. This gives you a direct understanding of the core ideas behind collaborative AI systems."
      ],
      "metadata": {
        "id": "xtPtB-SlBM27"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AjXQcnlHsPmK",
        "outputId": "af981508-7c78-4a40-93cc-dc2210497271"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==2.14.0\n",
            "  Downloading openai-2.14.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai==2.14.0) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai==2.14.0) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai==2.14.0) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai==2.14.0) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai==2.14.0) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai==2.14.0) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai==2.14.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai==2.14.0) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai==2.14.0) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai==2.14.0) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai==2.14.0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==2.14.0) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai==2.14.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai==2.14.0) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai==2.14.0) (0.4.2)\n",
            "Downloading openai-2.14.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 2.12.0\n",
            "    Uninstalling openai-2.12.0:\n",
            "      Successfully uninstalled openai-2.12.0\n",
            "Successfully installed openai-2.14.0\n"
          ]
        }
      ],
      "source": [
        "#@title Installing OpenAI and activating the API key\n",
        "!pip install openai==2.14.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports and API Key Setup\n",
        "# We will use the OpenAI library to interact with the LLM and Google Colab's\n",
        "# secret manager to securely access your API key.\n",
        "\n",
        "import os\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# Load the API key from Colab secrets, set the env var, then init the client\n",
        "try:\n",
        "    api_key = userdata.get(\"API_KEY\")\n",
        "    if not api_key:\n",
        "        raise userdata.SecretNotFoundError(\"API_KEY not found.\")\n",
        "\n",
        "    # Set environment variable for downstream tools/libraries\n",
        "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "\n",
        "    # Create client (will read from OPENAI_API_KEY)\n",
        "    client = OpenAI()\n",
        "    print(\"OpenAI API key loaded and environment variable set successfully.\")\n",
        "\n",
        "except userdata.SecretNotFoundError:\n",
        "    print('Secret \"API_KEY\" not found.')\n",
        "    print('Please add your OpenAI API key to the Colab Secrets Manager.')\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the API key: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9fssMtAwGlg",
        "outputId": "da5d8567-5583-4a7d-baf8-07d0e1a3209e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI API key loaded and environment variable set successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.Initializing the Client\n",
        "# ------------------------------------------------------------------------------\n",
        "# We'll need the `openai` library to communicate with the LLM.\n",
        "# Note: This notebook assumes you have already run a setup cell in your Colab\n",
        "# environment to load your API key from Colab Secrets into an environment\n",
        "# variable, as you specified.\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "import json\n",
        "\n",
        "# --- Initialize the OpenAI Client ---\n",
        "# The client will automatically read the OPENAI_API_KEY from your environment.\n",
        "client = OpenAI()\n",
        "print(\"OpenAI client initialized.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vO7u2nSmCkz4",
        "outputId": "794699be-b071-43af-df36-93772adf370d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI client initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.Defining the Protocol: The MCP Standard\n",
        "# ------------------------------------------------------------------------------\n",
        "# Before we build our agents, we must define the language they will speak.\n",
        "# MCP provides a simple, structured way to pass context. For this example,\n",
        "# our MCP message will be a Python dictionary with key fields.\n",
        "# ------------------------------------------------------------------------------\n",
        "def create_mcp_message(sender, content, metadata=None):\n",
        "    \"\"\"Creates a standardized MCP message.\"\"\"\n",
        "    return {\n",
        "        \"protocol_version\": \"1.0\",\n",
        "        \"sender\": sender,\n",
        "        \"content\": content,\n",
        "        \"metadata\": metadata or {}\n",
        "    }\n",
        "\n",
        "print(\"--- Example MCP Message (Our Simplified Version) ---\")\n",
        "example_mcp = create_mcp_message(\n",
        "    sender=\"Orchestrator\",\n",
        "    content=\"Research the benefits of the Mediterranean diet.\",\n",
        "    metadata={\"task_id\": \"T-123\", \"priority\": \"high\"}\n",
        ")\n",
        "print(json.dumps(example_mcp, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRLx7hw0Cuyd",
        "outputId": "5f306913-100d-40fb-e654-a74893050bda"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Example MCP Message (Our Simplified Version) ---\n",
            "{\n",
            "  \"protocol_version\": \"1.0\",\n",
            "  \"sender\": \"Orchestrator\",\n",
            "  \"content\": \"Research the benefits of the Mediterranean diet.\",\n",
            "  \"metadata\": {\n",
            "    \"task_id\": \"T-123\",\n",
            "    \"priority\": \"high\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3.Building the Agents: The Specialists\n",
        "# ------------------------------------------------------------------------------\n",
        "# Each agent is a function that takes an MCP message as input and returns one\n",
        "# as output. The core of each agent is a carefully crafted \"Semantic Blueprint\"\n",
        "# in the system prompt that defines its persona and task.\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "def call_llm(system_prompt, user_content):\n",
        "    \"\"\"A helper function to call the OpenAI API using the new client syntax.\"\"\"\n",
        "    try:\n",
        "        # Using the updated client.chat.completions.create method\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-5.2\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_content}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred with the API call: {e}\"\n",
        "\n",
        "# --- Agent 1: The Researcher ---\n",
        "def researcher_agent(mcp_input):\n",
        "    \"\"\"\n",
        "    This agent takes a research topic, finds information, and returns a summary.\n",
        "    \"\"\"\n",
        "    print(\"\\n[Researcher Agent Activated]\")\n",
        "    simulated_database = {\n",
        "        \"mediterranean diet\": \"The Mediterranean diet is rich in fruits, vegetables, whole grains, olive oil, and fish. Studies show it is associated with a lower risk of heart disease, improved brain health, and a longer lifespan. Key components include monounsaturated fats and antioxidants.\"\n",
        "    }\n",
        "    research_topic = mcp_input['content']\n",
        "    research_result = simulated_database.get(research_topic.lower(), \"No information found on this topic.\")\n",
        "    system_prompt = \"You are a research analyst. Your task is to synthesize the provided information into 3-4 concise bullet points. Focus on the key findings.\"\n",
        "    summary = call_llm(system_prompt, research_result)\n",
        "    print(f\"Research summary created for: '{research_topic}'\")\n",
        "    return create_mcp_message(\n",
        "        sender=\"ResearcherAgent\",\n",
        "        content=summary,\n",
        "        metadata={\"source\": \"Simulated Internal DB\"}\n",
        "    )\n",
        "\n",
        "# --- Agent 2: The Writer ---\n",
        "def writer_agent(mcp_input):\n",
        "    \"\"\"\n",
        "    This agent takes research findings and writes a short blog post.\n",
        "    \"\"\"\n",
        "    print(\"\\n[Writer Agent Activated]\")\n",
        "    research_summary = mcp_input['content']\n",
        "    system_prompt = \"You are a skilled content writer for a health and wellness blog. Your tone is engaging, informative, and encouraging. Your task is to take the following research points and write a short, appealing blog post (approx. 150 words) with a catchy title.\"\n",
        "    blog_post = call_llm(system_prompt, research_summary)\n",
        "    print(\"Blog post drafted.\")\n",
        "    return create_mcp_message(\n",
        "        sender=\"WriterAgent\",\n",
        "        content=blog_post,\n",
        "        metadata={\"word_count\": len(blog_post.split())}\n",
        "    )\n"
      ],
      "metadata": {
        "id": "sIwb2CHyC6x6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4.Building the Orchestrator: The Project Manager\n",
        "# ------------------------------------------------------------------------------\n",
        "# The Orchestrator manages the workflow. It calls the agents in the correct\n",
        "# order, passing context from one to the next using MCP messages.\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "def orchestrator(initial_goal):\n",
        "    \"\"\"\n",
        "    Manages the multi-agent workflow to achieve a high-level goal.\n",
        "    \"\"\"\n",
        "    print(\"=\"*50)\n",
        "    print(f\"[Orchestrator] Goal Received: '{initial_goal}'\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # --- Step 1: Orchestrator plans and calls the Researcher Agent ---\n",
        "    print(\"\\n[Orchestrator] Task 1: Research. Delegating to Researcher Agent.\")\n",
        "    research_topic = \"Mediterranean Diet\"\n",
        "    mcp_to_researcher = create_mcp_message(\n",
        "        sender=\"Orchestrator\",\n",
        "        content=research_topic\n",
        "    )\n",
        "    mcp_from_researcher = researcher_agent(mcp_to_researcher)\n",
        "    print(\"\\n[Orchestrator] Research complete. Received summary:\")\n",
        "    print(\"-\" * 20)\n",
        "    print(mcp_from_researcher['content'])\n",
        "    print(\"-\" * 20)\n",
        "\n",
        "    # --- Step 2: Orchestrator calls the Writer Agent ---\n",
        "    print(\"\\n[Orchestrator] Task 2: Write Content. Delegating to Writer Agent.\")\n",
        "    mcp_to_writer = create_mcp_message(\n",
        "        sender=\"Orchestrator\",\n",
        "        content=mcp_from_researcher['content']\n",
        "    )\n",
        "    mcp_from_writer = writer_agent(mcp_to_writer)\n",
        "    print(\"\\n[Orchestrator] Writing complete.\")\n",
        "\n",
        "    # --- Step 3: Orchestrator presents the final result ---\n",
        "    final_output = mcp_from_writer['content']\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"[Orchestrator] Workflow Complete. Final Output:\")\n",
        "    print(\"=\"*50)\n",
        "    print(final_output)"
      ],
      "metadata": {
        "id": "6CYzPh-lDFfb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5.Run the System\n",
        "# ------------------------------------------------------------------------------\n",
        "# Let's give our Orchestrator a high-level goal and watch the agent team work.\n",
        "# ------------------------------------------------------------------------------\n",
        "# Note: the goal is hard coded for this exmaple before we make it a variable in the subsequent notebooks\n",
        "user_goal = \"Create a blog post about the benefits of the Mediterranean diet.\"\n",
        "orchestrator(user_goal)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "[Orchestrator] Goal Received: 'Create a blog post about the benefits of the Mediterranean diet.'\n",
            "==================================================\n",
            "\n",
            "[Orchestrator] Task 1: Research. Delegating to Researcher Agent.\n",
            "\n",
            "[Researcher Agent Activated]\n",
            "Research summary created for: 'Mediterranean Diet'\n",
            "\n",
            "[Orchestrator] Research complete. Received summary:\n",
            "--------------------\n",
            "- The Mediterranean diet emphasizes fruits, vegetables, whole grains, olive oil, and fish.  \n",
            "- Research links it to a lower risk of heart disease and a longer lifespan.  \n",
            "- Studies also associate it with improved brain health.  \n",
            "- Benefits are attributed in part to monounsaturated fats and antioxidants.\n",
            "--------------------\n",
            "\n",
            "[Orchestrator] Task 2: Write Content. Delegating to Writer Agent.\n",
            "\n",
            "[Writer Agent Activated]\n",
            "Blog post drafted.\n",
            "\n",
            "[Orchestrator] Writing complete.\n",
            "\n",
            "==================================================\n",
            "[Orchestrator] Workflow Complete. Final Output:\n",
            "==================================================\n",
            "## Eat Like the Mediterranean: A Simple Recipe for a Healthier Heart and Brain\n",
            "\n",
            "If you’re looking for an eating style that feels satisfying *and* supports long-term wellness, the Mediterranean diet is a great place to start. This approach centers on colorful fruits and vegetables, hearty whole grains, nourishing olive oil, and protein-rich fish—foods that are both flavorful and easy to build into everyday meals.\n",
            "\n",
            "Research has consistently linked the Mediterranean diet to a lower risk of heart disease and even a longer lifespan. That’s great news for anyone aiming to protect their cardiovascular health without turning meals into a chore. Even better, studies suggest it may support brain health, too—an important benefit as we age.\n",
            "\n",
            "Why does it work? A big part of the magic comes from monounsaturated fats (especially from olive oil and fish) plus a wide range of antioxidants found in plant foods. Start small: swap butter for olive oil, add an extra vegetable, and aim for fish a couple times a week.\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "id": "eNHm5qkhSggG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c9a45b5-421a-4860-d98f-8897f23f81dc"
      }
    }
  ]
}